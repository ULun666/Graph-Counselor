{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pay attention to the reproducibility !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=f\"/shared/data3/bowenj4/llm-graph-plugin/data/processed_data/legal\"\n",
    "downstream_dir=f\"/shared/data3/bowenj4/llm-graph-plugin/data/raw_data/legal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read processed graph\n",
    "#graph = pickle.load(open(os.path.join(data_dir, 'graph.pkl'),\"rb\"))\n",
    "graph = json.load(open(os.path.join(data_dir, 'graph.json')))\n",
    "print(graph.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for opcid in list(graph['opinion_cluster_nodes'].keys())[:1000]:\n",
    "    if isinstance(graph['opinion_cluster_nodes'][opcid]['features']['syllabus'], str):\n",
    "        print(opcid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['opinion_cluster_nodes']['opc-8599951']['neighbors'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['opinion_cluster_nodes']['opc-4601433']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['docket_nodes']['d-65862636']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['opinion_cluster_nodes']['opc-8599951']['neighbors']['docket']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['opinion_nodes']['op-7344185']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['opinion_cluster_nodes']['opc-6381448']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(graph['opinion_nodes'].keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['opinion_nodes']['op-8044194']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph['court_nodes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check the ids\n",
    "id_set = set()\n",
    "\n",
    "for k in graph:\n",
    "    print(k)\n",
    "    for idd in tqdm(graph[k]):\n",
    "        assert idd not in id_set\n",
    "        id_set.add(idd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_int(start, end, num, target_list):\n",
    "    res = set()\n",
    "    while len(res) < num:\n",
    "        tmp = random.randint(start, end)\n",
    "        if tmp not in res:\n",
    "            res.add(tmp)\n",
    "    return [target_list[i] for i in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    return text\n",
    "\n",
    "def ignore_text(text):\n",
    "    if not isinstance(text, str) and math.isnan(text):\n",
    "        return True\n",
    "    if isinstance(text, str) and len(text) == 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplication\n",
    "opinion_text_dict = defaultdict(int)\n",
    "for opinion_id in tqdm(graph['opinion_nodes'].keys()):\n",
    "    opinion_text = graph['opinion_nodes'][opinion_id]['features']['plain_text']\n",
    "    opinion_text_dict[opinion_text] += 1\n",
    "\n",
    "opinion_cluster_text_dict= defaultdict(int)\n",
    "for opinion_cluster_id in tqdm(graph['opinion_cluster_nodes'].keys()):\n",
    "    opinion_cluster_text = graph['opinion_cluster_nodes'][opinion_cluster_id]['features']['syllabus']\n",
    "    opinion_cluster_text_dict[opinion_cluster_text] += 1\n",
    "\n",
    "# truncation function\n",
    "from transformers import AutoTokenizer\n",
    "truncate_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "def truncate(text, max_len=256):\n",
    "    return truncate_tokenizer.decode(truncate_tokenizer.encode(text, truncation=True, max_length=max_len, add_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_generated_data = {} # key: triple (question (str), answer (str)), value: generated data (List)\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design questions (one type of question in one cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (easy): what is the start date of court xxx?\n",
    "\n",
    "random.seed(2023)\n",
    "\n",
    "question = \"what is the start date of court {court_name}?\"\n",
    "answer = \"{start_date}\"\n",
    "generated_data = []\n",
    "\n",
    "court_ids = list(graph['court_nodes'].keys())\n",
    "random.shuffle(court_ids)\n",
    "\n",
    "for court_id in court_ids:\n",
    "    court_name = graph['court_nodes'][court_id]['features']['full_name']\n",
    "    start_date = graph['court_nodes'][court_id]['features']['start_date']\n",
    "    if isinstance(start_date, str):\n",
    "        generated_data.append({\"court_name\":court_name, \"start_date\": start_date})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (easy): what is the end date of court xxx?\n",
    "\n",
    "random.seed(2024)\n",
    "\n",
    "question = \"what is the end date of court {court_name}?\"\n",
    "answer = \"{end_date}\"\n",
    "generated_data = []\n",
    "\n",
    "court_ids = list(graph['court_nodes'].keys())\n",
    "random.shuffle(court_ids)\n",
    "\n",
    "for court_id in court_ids:\n",
    "    court_name = graph['court_nodes'][court_id]['features']['full_name']\n",
    "    end_date = graph['court_nodes'][court_id]['features']['end_date']\n",
    "    if isinstance(end_date, str):\n",
    "        generated_data.append({\"court_name\":court_name, \"end_date\": end_date})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (easy): what is the citation string of court xxx?\n",
    "\n",
    "random.seed(2025)\n",
    "\n",
    "question = \"what is the citation string of court {court_name}?\"\n",
    "answer = \"{citation_string}\"\n",
    "generated_data = []\n",
    "\n",
    "court_ids = list(graph['court_nodes'].keys())\n",
    "random.shuffle(court_ids)\n",
    "\n",
    "for court_id in court_ids:\n",
    "    court_name = graph['court_nodes'][court_id]['features']['full_name']\n",
    "    citation_string = graph['court_nodes'][court_id]['features']['citation_string']\n",
    "\n",
    "    if ignore_text(citation_string):\n",
    "        continue\n",
    "\n",
    "    generated_data.append({\"court_name\":court_name, \"citation_string\": citation_string})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (easy): which court is handling the case listed under the PACER docket number xxx?\n",
    "\n",
    "random.seed(2026)\n",
    "\n",
    "question = \"which court is handling the case listed under the PACER docket number {pacer_id}?\"\n",
    "answer = \"{court_name}\"\n",
    "generated_data = []\n",
    "\n",
    "docket_ids_list = list(graph['docket_nodes'].keys())\n",
    "docket_ids = random_int(0, len(docket_ids_list)-1, 1000 * k, docket_ids_list)\n",
    "\n",
    "for docket_id in docket_ids:\n",
    "    pacer_id = graph['docket_nodes'][docket_id]['features']['pacer_case_id']\n",
    "    assert len(graph['docket_nodes'][docket_id]['neighbors']['court']) == 1\n",
    "    court_id = graph['docket_nodes'][docket_id]['neighbors']['court'][0]\n",
    "    \n",
    "    if ignore_text(pacer_id):\n",
    "        continue\n",
    "\n",
    "    court_name = graph['court_nodes'][court_id]['features']['full_name']\n",
    "    generated_data.append({\"pacer_id\": pacer_id, \"court_name\": court_name})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (easy): Who are the attorneys for the case corresponding to this opinion cluster?\n",
    "\n",
    "random.seed(2027)\n",
    "\n",
    "question = \"Who are the attorneys for the case corresponding to this opinion cluster: {opinion_cluster_text}?\"\n",
    "answer = \"{attorneys}\"\n",
    "generated_data = []\n",
    "\n",
    "opinion_cluster_ids_list = list(graph['opinion_cluster_nodes'].keys())\n",
    "# random.shuffle(opinion_ids)\n",
    "opinion_cluster_ids = random_int(0, len(opinion_cluster_ids_list)-1, 100 * k, opinion_cluster_ids_list)\n",
    "\n",
    "for opinion_cluster_id in opinion_cluster_ids:\n",
    "    opinion_cluster_text = graph['opinion_cluster_nodes'][opinion_cluster_id]['features']['syllabus']\n",
    "    if ignore_text(opinion_cluster_text) or opinion_cluster_text_dict[opinion_cluster_text] != 1:\n",
    "        continue\n",
    "\n",
    "    attorneys = graph['opinion_cluster_nodes'][opinion_cluster_id]['features']['attorneys']\n",
    "    if ignore_text(attorneys):\n",
    "        continue\n",
    "\n",
    "    generated_data.append({\"opinion_cluster_text\":truncate(opinion_cluster_text), \"attorneys\": attorneys})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): Which members of the judiciary are responsible for the group of rulings that includes the following opinion: {opinion_text}?\n",
    "\n",
    "random.seed(2027)\n",
    "\n",
    "question = \"Which members of the judiciary are responsible for the group of rulings that includes the following opinion: {opinion_text}\"\n",
    "answer = \"{judges}\"\n",
    "generated_data = []\n",
    "\n",
    "opinion_ids_list = list(graph['opinion_nodes'].keys())\n",
    "# random.shuffle(opinion_ids)\n",
    "opinion_ids = random_int(0, len(opinion_ids_list)-1, 5 * k, opinion_ids_list)\n",
    "\n",
    "for opinion_id in opinion_ids:\n",
    "    opinion_text = graph['opinion_nodes'][opinion_id]['features']['plain_text']\n",
    "    if ignore_text(opinion_text) or opinion_text_dict[opinion_text] != 1:\n",
    "        continue\n",
    "\n",
    "    assert len(graph['opinion_nodes'][opinion_id]['neighbors']['opinion_cluster']) == 1\n",
    "    opinion_cluster_id = graph['opinion_nodes'][opinion_id]['neighbors']['opinion_cluster'][0]\n",
    "    judges = graph['opinion_cluster_nodes'][opinion_cluster_id]['features']['judges']\n",
    "    if ignore_text(judges):\n",
    "        continue\n",
    "\n",
    "    generated_data.append({\"opinion_text\":truncate(opinion_text), \"judges\": judges})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): What docket includes this opinion: xxxx? Please answer with the pacer case ID.\n",
    "\n",
    "random.seed(2028)\n",
    "\n",
    "question = \"What docket includes this opinion: {opinion_plain_text}? Please answer with the pacer case ID.\"\n",
    "answer = \"{pacer_id}\"\n",
    "generated_data = []\n",
    "\n",
    "opinion_ids_list = list(graph['opinion_nodes'].keys())\n",
    "opinion_ids = random_int(0, len(opinion_ids_list)-1, 10000, opinion_ids_list)\n",
    "\n",
    "for opinion_id in opinion_ids:\n",
    "    opinion_content = graph['opinion_nodes'][opinion_id]['features']['plain_text']\n",
    "    assert len(graph['opinion_nodes'][opinion_id]['neighbors']['opinion_cluster']) == 1\n",
    "\n",
    "    opinion_cluster_id = graph['opinion_nodes'][opinion_id]['neighbors']['opinion_cluster'][0]\n",
    "    assert len(graph['opinion_cluster_nodes'][opinion_cluster_id]['neighbors']['docket']) == 1\n",
    "\n",
    "    docket_id = graph['opinion_cluster_nodes'][opinion_cluster_id]['neighbors']['docket'][0]\n",
    "    pacer_id = graph['docket_nodes'][docket_id]['features']['pacer_case_id']\n",
    "\n",
    "    if ignore_text(opinion_content) or ignore_text(pacer_id) or opinion_text_dict[opinion_content] != 1:\n",
    "        continue\n",
    "\n",
    "    # raise ValueError('you may add a text processing function here')\n",
    "    opinion_content = text_process(opinion_content)\n",
    "\n",
    "    generated_data.append({\"opinion_plain_text\": truncate(opinion_content), \"pacer_id\": pacer_id})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): Which court is this opinion cluster syllabus published: {opinion_cluster_text}? Please answer the court full name.\n",
    "\n",
    "random.seed(2029)\n",
    "\n",
    "question = \"Which court is this opinion cluster syllabus published: {opinion_cluster_text}?\"\n",
    "answer = \"{court_name}\"\n",
    "generated_data = []\n",
    "\n",
    "opinion_cluster_ids_list = list(graph['opinion_cluster_nodes'].keys())\n",
    "#random.shuffle(opinion_cluster_ids)\n",
    "opinion_cluster_ids = random_int(0, len(opinion_cluster_ids_list)-1, 1000, opinion_cluster_ids_list)\n",
    "\n",
    "\n",
    "for opinion_cluster_id in opinion_cluster_ids:\n",
    "    opinion_cluster_content = graph['opinion_cluster_nodes'][opinion_cluster_id]['features']['syllabus']\n",
    "\n",
    "    assert len(graph['opinion_cluster_nodes'][opinion_cluster_id]['neighbors']['docket']) == 1\n",
    "    docket_id = graph['opinion_cluster_nodes'][opinion_cluster_id]['neighbors']['docket'][0]\n",
    "    \n",
    "    assert len(graph['docket_nodes'][docket_id]['neighbors']['court']) == 1\n",
    "    court_id = graph['docket_nodes'][docket_id]['neighbors']['court'][0]\n",
    "    court_name = graph['court_nodes'][court_id]['features']['full_name']\n",
    "\n",
    "    if ignore_text(opinion_cluster_content) or opinion_cluster_text_dict[opinion_cluster_content] != 1:\n",
    "        continue\n",
    "\n",
    "    # raise ValueError('you may add a text processing function here')\n",
    "    opinion_cluster_content = text_process(opinion_cluster_content)\n",
    "\n",
    "    generated_data.append({\"opinion_cluster_text\": truncate(opinion_cluster_content), \"court_name\": court_name})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## easy questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): How many dockets have been processed in court xxx?\n",
    "\n",
    "random.seed(2030)\n",
    "\n",
    "question = \"How many dockets have been processed in court {court_name}?\"\n",
    "answer = \"{num}\"\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "court_ids_list = list(graph['court_nodes'].keys())\n",
    "#random.shuffle(court_ids)\n",
    "court_ids = random_int(0, len(court_ids_list)-1, 100 * k, court_ids_list)\n",
    "\n",
    "for court_id in court_ids:\n",
    "    court_name = graph['court_nodes'][court_id]['features']['full_name']\n",
    "\n",
    "    num = len(graph['court_nodes'][court_id]['neighbors']['docket'])\n",
    "\n",
    "    if num < 30 and num > 1:\n",
    "        generated_data.append({\"court_name\": court_name, \"num\": num})\n",
    "    #generated_data.append({\"court_name\": court_name, \"num\": num})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data\n",
    "\n",
    "## TODO: we can add more constrains later, e.g., in year xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): How many opinions are citing this opinion xxx?\n",
    "\n",
    "random.seed(2031)\n",
    "\n",
    "question = \"How many opinions are citing this opinion: {opinion_text}?\"\n",
    "answer = \"{num}\"\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "opinion_ids_list = list(graph['opinion_nodes'].keys())\n",
    "#random.shuffle(court_ids)\n",
    "opinion_ids = random_int(0, len(opinion_ids_list)-1, 1000, opinion_ids_list)\n",
    "\n",
    "for opinion_id in opinion_ids:\n",
    "    opinion_text = graph['opinion_nodes'][opinion_id]['features']['plain_text']\n",
    "\n",
    "    if ignore_text(opinion_text) or opinion_text_dict[opinion_text] != 1:\n",
    "        continue\n",
    "\n",
    "    num = len(graph['opinion_nodes'][opinion_id]['neighbors']['cited_by'])\n",
    "\n",
    "    if num < 30 and num > 1:\n",
    "        opinion_text = text_process(opinion_text)\n",
    "        generated_data.append({\"opinion_text\": truncate(opinion_text), \"num\": num})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data\n",
    "\n",
    "## TODO: we can add more constrains later, e.g., in year xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## medium questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): How many times has the xxx case been judged in different courts?\n",
    "\n",
    "random.seed(2032)\n",
    "\n",
    "question = \"How many times has the case {case_name} been judged in different courts?\"\n",
    "answer = \"{num}\"\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "opinion_cluster_ids_list = list(graph['opinion_cluster_nodes'].keys())\n",
    "opinion_cluster_ids = random_int(0, len(opinion_cluster_ids_list)-1, 5 * k, opinion_cluster_ids_list)\n",
    "seen_name = set()\n",
    "\n",
    "case_court_set = defaultdict(set)\n",
    "for op in tqdm(opinion_cluster_ids_list):\n",
    "    case_name = graph['opinion_cluster_nodes'][op]['features']['case_name']\n",
    "    docket_id = graph['opinion_cluster_nodes'][op]['neighbors']['docket']\n",
    "    assert len(docket_id) == 1\n",
    "    docket_id = docket_id[0]\n",
    "    court_id = graph['docket_nodes'][docket_id]['neighbors']['court']\n",
    "    assert len(court_id) == 1\n",
    "    court_id = court_id[0]\n",
    "    case_court_set[case_name].add(graph['court_nodes'][court_id]['features']['full_name'])\n",
    "\n",
    "for opinion_cluster_id in opinion_cluster_ids:\n",
    "    case_name = graph['opinion_cluster_nodes'][opinion_cluster_id]['features']['case_name']\n",
    "\n",
    "    num = len(case_court_set[case_name])\n",
    "    if num > 10 or num < 2 or case_name in seen_name:\n",
    "        continue\n",
    "\n",
    "    generated_data.append({\"case_name\": case_name, \"num\": num})\n",
    "    seen_name.add(case_name)\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data\n",
    "\n",
    "## TODO: we can add more constrains later, e.g., in year xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): How many opinions are contained in the opinion clusters about {case_name}?\n",
    "\n",
    "random.seed(2033)\n",
    "\n",
    "question = \"How many opinions are contained in the opinion clusters about {case_name}?\"\n",
    "answer = \"{num}\"\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "opinion_cluster_ids_list = list(graph['opinion_cluster_nodes'].keys())\n",
    "opinion_cluster_ids = random_int(0, len(opinion_cluster_ids_list)-1, 5 * k, opinion_cluster_ids_list)\n",
    "seen_name = set()\n",
    "\n",
    "case_opinion_num = defaultdict(int)\n",
    "for op in tqdm(opinion_cluster_ids_list):\n",
    "    case_name = graph['opinion_cluster_nodes'][op]['features']['case_name']\n",
    "    opinion_ids = graph['opinion_cluster_nodes'][op]['neighbors']['opinion']\n",
    "    case_opinion_num[case_name] += len(opinion_ids)\n",
    "\n",
    "for opinion_cluster_id in opinion_cluster_ids:\n",
    "    case_name = graph['opinion_cluster_nodes'][opinion_cluster_id]['features']['case_name']\n",
    "\n",
    "    num = case_opinion_num[case_name]\n",
    "    if num > 10 or num < 2 or case_name in seen_name:\n",
    "        continue\n",
    "\n",
    "    generated_data.append({\"case_name\": case_name, \"num\": num})\n",
    "    seen_name.add(case_name)\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data\n",
    "\n",
    "## TODO: we can add more constrains later, e.g., in year xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): How many opinions are contained in the opinion cluster with syllabus {opinion_cluster_text}?\n",
    "\n",
    "random.seed(2034)\n",
    "\n",
    "question = \"How many opinions are contained in the opinion cluster with syllabus: {opinion_cluster_text}?\"\n",
    "answer = \"{num}\"\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "opinion_cluster_ids_list = list(graph['opinion_cluster_nodes'].keys())\n",
    "opinion_cluster_ids = random_int(0, len(opinion_cluster_ids_list)-1, 100000, opinion_cluster_ids_list)\n",
    "seen_name = set()\n",
    "\n",
    "cluster_text_num = defaultdict(int)\n",
    "cluster_opinion_num = defaultdict(int)\n",
    "for op in tqdm(opinion_cluster_ids_list):\n",
    "    cluster_text = graph['opinion_cluster_nodes'][op]['features']['syllabus']\n",
    "    cluster_text_num[cluster_text] += 1\n",
    "\n",
    "    opinion_ids = graph['opinion_cluster_nodes'][op]['neighbors']['opinion']\n",
    "    cluster_opinion_num[cluster_text] += len(opinion_ids)\n",
    "\n",
    "for opinion_cluster_id in opinion_cluster_ids:\n",
    "    cluster_text = graph['opinion_cluster_nodes'][opinion_cluster_id]['features']['syllabus']\n",
    "    if cluster_text_num[cluster_text] > 1:\n",
    "        continue\n",
    "\n",
    "    num = cluster_opinion_num[cluster_text]\n",
    "    if num > 10 or num < 2 or cluster_text in seen_name:\n",
    "        continue\n",
    "\n",
    "    generated_data.append({\"opinion_cluster_text\": truncate(cluster_text), \"num\": num})\n",
    "    seen_name.add(cluster_text)\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data\n",
    "\n",
    "## TODO: we can add more constrains later, e.g., in year xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): How many opinions are contained in the opinion cluster with opinion xxx?\n",
    "\n",
    "random.seed(2035)\n",
    "\n",
    "question = \"How many opinions are contained in the opinion cluster with opinion {opinion_text}?\"\n",
    "answer = \"{num}\"\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "opinion_ids_list = list(graph['opinion_nodes'].keys())\n",
    "opinion_ids = random_int(0, len(opinion_ids_list)-1, 100000, opinion_ids_list)\n",
    "seen_name = set()\n",
    "\n",
    "opinion_text_num = defaultdict(int)\n",
    "for op in tqdm(opinion_ids_list):\n",
    "    opinion_text = graph['opinion_nodes'][op]['features']['plain_text']\n",
    "    opinion_text_num[opinion_text] += 1\n",
    "\n",
    "for opinion_id in opinion_ids:\n",
    "    opinion_text = graph['opinion_nodes'][opinion_id]['features']['plain_text']\n",
    "    if opinion_text_num[opinion_text] > 1:\n",
    "        continue\n",
    "\n",
    "    opinion_cluster_id = graph['opinion_nodes'][opinion_id]['neighbors']['opinion_cluster']\n",
    "    assert len(opinion_cluster_id) == 1\n",
    "    opinion_cluster_id = opinion_cluster_id[0]\n",
    "\n",
    "    num = len(graph['opinion_cluster_nodes'][opinion_cluster_id]['neighbors']['opinion'])\n",
    "    if num > 10 or num < 2 or opinion_text in seen_name:\n",
    "        continue\n",
    "\n",
    "    generated_data.append({\"opinion_text\": truncate(opinion_text), \"num\": num})\n",
    "    seen_name.add(opinion_text)\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data\n",
    "\n",
    "## TODO: we can add more constrains later, e.g., in year xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): Which court is this opinion ({opinion text}) published?\n",
    "\n",
    "random.seed(2036)\n",
    "\n",
    "question = \"Which court is this opinion ({opinion_text}) published?\"\n",
    "answer = \"{court_name}\"\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "opinion_ids_list = list(graph['opinion_nodes'].keys())\n",
    "opinion_ids = random_int(0, len(opinion_ids_list)-1, 100000, opinion_ids_list)\n",
    "seen_name = set()\n",
    "\n",
    "opinion_text_num = defaultdict(int)\n",
    "for op in tqdm(opinion_ids_list):\n",
    "    opinion_text = graph['opinion_nodes'][op]['features']['plain_text']\n",
    "    opinion_text_num[opinion_text] += 1\n",
    "\n",
    "for opinion_id in opinion_ids:\n",
    "    opinion_text = graph['opinion_nodes'][opinion_id]['features']['plain_text']\n",
    "    if opinion_text_num[opinion_text] > 1:\n",
    "        continue\n",
    "\n",
    "    opinion_cluster_id = graph['opinion_nodes'][opinion_id]['neighbors']['opinion_cluster']\n",
    "    assert len(opinion_cluster_id) == 1\n",
    "    opinion_cluster_id = opinion_cluster_id[0]\n",
    "\n",
    "    docket_id = graph['opinion_cluster_nodes'][opinion_cluster_id]['neighbors']['docket']\n",
    "    assert len(docket_id) == 1\n",
    "    docket_id = docket_id[0]\n",
    "\n",
    "    court_id = graph['docket_nodes'][docket_id]['neighbors']['court']\n",
    "    assert len(court_id) == 1\n",
    "    court_id = court_id[0]\n",
    "    court_name = graph['court_nodes'][court_id]['features']['full_name']\n",
    "\n",
    "    if opinion_text in seen_name:\n",
    "        continue\n",
    "\n",
    "    generated_data.append({\"opinion_text\": truncate(opinion_text), \"court_name\": court_name})\n",
    "    seen_name.add(opinion_text)\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data\n",
    "\n",
    "## TODO: we can add more constrains later, e.g., in year xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## question (medium): What is the preferred cited court of judges in court {court_name}?\n",
    "\n",
    "random.seed(2037)\n",
    "\n",
    "question = \"What is the preferred court to cite of judges in court {source_court_name}?\"\n",
    "answer = \"{target_court_name}\"\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "opinion_ids_list = list(graph['opinion_nodes'].keys())\n",
    "#opinion_ids = random_int(0, len(opinion_ids_list)-1, 10000, opinion_ids_list)\n",
    "court_ids_list = list(graph['court_nodes'].keys())\n",
    "court_ids = random_int(0, len(court_ids_list)-1, 1000, court_ids_list)\n",
    "seen_name = set()\n",
    "\n",
    "def get_court_name(opinion_id):\n",
    "    opinion_cluster_id = graph['opinion_nodes'][opinion_id]['neighbors']['opinion_cluster']\n",
    "    assert len(opinion_cluster_id) == 1\n",
    "    opinion_cluster_id = opinion_cluster_id[0]\n",
    "\n",
    "    docket_id = graph['opinion_cluster_nodes'][opinion_cluster_id]['neighbors']['docket']\n",
    "    assert len(docket_id) == 1\n",
    "    docket_id = docket_id[0]\n",
    "\n",
    "    court_id = graph['docket_nodes'][docket_id]['neighbors']['court']\n",
    "    assert len(court_id) == 1\n",
    "    court_id = court_id[0]\n",
    "    court_name = graph['court_nodes'][court_id]['features']['full_name']\n",
    "    return court_name\n",
    "\n",
    "#opinion_text_num = defaultdict(int)\n",
    "#court2court = defaultdict(defaultdict(int))\n",
    "court2court = dict()\n",
    "for op in tqdm(opinion_ids_list):\n",
    "    #opinion_text = graph['opinion_nodes'][op]['features']['plain_text']\n",
    "    #opinion_text_num[opinion_text] += 1\n",
    "\n",
    "    # source\n",
    "    source_court_name = get_court_name(op)\n",
    "    for ref in graph['opinion_nodes'][op]['neighbors']['reference']:\n",
    "        target_court_name = get_court_name(ref)\n",
    "        if source_court_name not in court2court:\n",
    "            court2court[source_court_name] = defaultdict(int)\n",
    "\n",
    "        court2court[source_court_name][target_court_name] += 1\n",
    "\n",
    "for court_id in court_ids:\n",
    "    court_name = graph['court_nodes'][court_id]['features']['full_name']\n",
    "\n",
    "    if court_name in seen_name or court_name not in court2court:\n",
    "        continue\n",
    "\n",
    "    candidate = [(tgt_court, court2court[court_name][tgt_court]) for tgt_court in court2court[court_name]]\n",
    "    candidate.sort(key= lambda x: -x[1])\n",
    "\n",
    "    if candidate[0][1] == candidate[1][1]:\n",
    "        continue\n",
    "\n",
    "    generated_data.append({\"source_court_name\": court_name, \"target_court_name\": candidate[0][0]})\n",
    "    seen_name.add(court_name)\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data\n",
    "\n",
    "## TODO: we can add more constrains later, e.g., in year xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inductive Reasoning (hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "lp_cls_dataset = load_dataset(\"nguha/legalbench\", 'citation_prediction_classification', split=\"test\")\n",
    "lp_open_dataset = load_dataset(\"nguha/legalbench\", 'citation_prediction_open', split=\"test\")\n",
    "\n",
    "case_name_set = set()\n",
    "docket_ids_list = list(graph['docket_nodes'].keys())\n",
    "\n",
    "for docket_id in tqdm(docket_ids_list):\n",
    "    case_name = graph['docket_nodes'][docket_id]['features']['case_name']\n",
    "    case_name_set.add(case_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citation classification\n",
    "## question (hard): Is the given sentence supported by the given case? Sentence: {text}, case: {case_name}.\n",
    "\n",
    "random.seed(2038)\n",
    "\n",
    "question = \"Is the given sentence supported by the given case? Sentence: {text}, case: {case_name}.\"\n",
    "answer = \"{answer}\"\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "exist_data = []\n",
    "for row in lp_cls_dataset:\n",
    "    if row['citation'] in case_name_set:\n",
    "        exist_data.append((row['text'], row['citation'], row['answer']))\n",
    "random.shuffle(exist_data)\n",
    "print(len(exist_data))\n",
    "\n",
    "for d in exist_data[:k]:\n",
    "    generated_data.append({\"text\": d[0], \"case_name\": d[1], \"answer\": d[2]})\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citation open\n",
    "## question (hard): Find a case which can support this sentence: {text}.\n",
    "\n",
    "random.seed(2039)\n",
    "\n",
    "question = \"Find a case which can support this sentence: {text}.\"\n",
    "answer = \"{case_name}\"\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "exist_data = []\n",
    "for row in lp_open_dataset:\n",
    "    if row['answer'] in case_name_set:\n",
    "        exist_data.append((row['text'], row['answer']))\n",
    "random.shuffle(exist_data)\n",
    "print(len(exist_data))\n",
    "\n",
    "for d in exist_data[:k]:\n",
    "    generated_data.append({\"text\": d[0], \"case_name\": d[1]})\n",
    "\n",
    "assert len(generated_data) == k\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save\n",
    "pickle.dump(all_generated_data, open(os.path.join(data_dir, 'preprocess_samples.pkl'), 'wb'))\n",
    "\n",
    "print('Saving file of #questions, ', len(all_generated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nodes: opinion, opinion_cluster, court, docket\n",
    "## opinion features: plain_text\n",
    "## opinion_cluster features: syllabus, judges, case_name\n",
    "## court: full_name, start_date, end_date, citation_string\n",
    "## docket: pacer_case_id, case_name_full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
